{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schedule Azure Machine Learning Pipelines\n",
    "\n",
    "In this tutorial, you will learn how to schedule Azure Machine Learning pipelines. The example does a simple data-preparation task every minute. Raw data are read from a CSV file, normalized, and output to another CSV file for downstream processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain\n",
    "\n",
    "The fake domain of this tutorial relates to colors. We are pretending that our input data consists of a set of \"votes\" for a color that we need to preprocess for our downstream ML system. The following cells reflect the contents of the **pipeline_src/color.py** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, unique\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  @unique\n",
    "class Color(Enum) : \n",
    "    Red = 0 \n",
    "    Orange = 1 \n",
    "    Yellow = 2\n",
    "    Green = 3\n",
    "    Blue = 4\n",
    "    Indigo = 5\n",
    "    Violet = 6\n",
    "    \n",
    "    @classmethod\n",
    "    def randn_color(cls) : \n",
    "        v = np.random.randn()\n",
    "        c = next((c for c in Color if v < (0.65 * (float(c.value) - 2.5))), Color.Violet)\n",
    "        return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that our method `randn_color()` produces a normally-distributed shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = list(Color.randn_color().value for _ in range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 61., 106., 201., 287., 185., 116.,  44.]),\n",
       " array([0.        , 0.85714286, 1.71428571, 2.57142857, 3.42857143,\n",
       "        4.28571429, 5.14285714, 6.        ]),\n",
       " <a list of 7 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cs,len(Color))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's going on in the training script...\n",
    "\n",
    "This section reflect the functions in the **pipeline_src/preprocessing.py** file. \n",
    "\n",
    "To simulate some out-of-process data collection, the file **preprocessing.py** generates fake data and writes it to a file **unprocessed_data.csv**. \n",
    "\n",
    "Then, **preprocessing.py** reads that file, and \"prepares the data for ML.\" In this case, it does some data transformation and normalizes the results. It writes the results to **processed_data.csv**. \n",
    "\n",
    "One scenario might be retraining or inferencing periodically. Another scenario, if data preparation was a very expensive step, would be to run a preprocessing pipeline on one schedule and retraining on another, slower, schedule. Azure ML Pipelines give you the flexibility to tackle either of those scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime,timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fake_data(minutes, mu, sigma) :\n",
    "    end_time = datetime.now()\n",
    "    start_time = end_time - timedelta(minutes=minutes)\n",
    "    # Generate a random amount of data\n",
    "    amount_of_fake_data = minutes * int(mu + sigma * np.random.randn())\n",
    "    # Generate at least 1 element\n",
    "    amount_of_fake_data = 1 if amount_of_fake_data < 1 else amount_of_fake_data\n",
    "    arrival_times = np.arange(start_time, end_time, timedelta(minutes = minutes / amount_of_fake_data)).astype(datetime)\n",
    "    color_votes = list(Color.randn_color().name for _ in range(amount_of_fake_data))\n",
    "    time_and_vote = zip(arrival_times, color_votes)\n",
    "    return time_and_vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`generate_fake_data()` creates a sequence of tuples. Each tuple has an arrival time and a \"vote\" for a particular color. The arrival times are arrive over the past `minutes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2019, 10, 2, 9, 5, 21, 558062), 'Blue'),\n",
       " (datetime.datetime(2019, 10, 2, 9, 5, 41, 558062), 'Blue'),\n",
       " (datetime.datetime(2019, 10, 2, 9, 6, 1, 558062), 'Yellow')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(generate_fake_data(1, 5, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_data(storage_dir) : \n",
    "    input_data_file = 'unprocessed_data.csv'\n",
    "    input_path = os.path.join(storage_dir, input_data_file)\n",
    "    # If first time, generate a bit more data \n",
    "    minutes_back = 1 if os.path.exists(input_path) else 10 \n",
    "    data = generate_fake_data(minutes_back, 100, 50)\n",
    "    with open(input_path, mode='w+') as f : \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_data('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fake_data()` creates or appends to the file `unprocessed_data.csv` in `storage_dir`, adding the results of some amount of `generate_fake_data()`. This `unprocessed_data.csv` file stands in for the output of some external datasource (Web site, field data, etc.)\n",
    "\n",
    "```\n",
    "2019-09-30 14:10:00.673782,Green\n",
    "2019-09-30 14:10:01.805857,Yellow\n",
    "2019-09-30 14:10:02.937932,Indigo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "The goal of this section is to read the unprocessed data and do some kind of \"preparation\" for ML. In this contrived situation, the steps are:\n",
    "\n",
    "* Read the raw data\n",
    "* Transform the human-readable record times into UNIX timestamp values \n",
    "* Transform the human-readable color \"vote\" into a numeric value\n",
    "* Normalize both the timestamps and votes \n",
    "* Write the processed data \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data(storage_dir) : \n",
    "    input_data_file = 'unprocessed_data.csv'\n",
    "    input_path = os.path.join(storage_dir, input_data_file)\n",
    "    if os.path.exists(input_path) : \n",
    "        with open(input_path, mode='r') as f : \n",
    "            reader = csv.reader(f)\n",
    "            return list(reader)\n",
    "    else :\n",
    "        # If file doesn't exist, return empty list \n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2019-10-02 09:05:21.576713', 'Orange'],\n",
       " ['2019-10-02 09:05:23.290999', 'Yellow'],\n",
       " ['2019-10-02 09:05:25.005285', 'Red'],\n",
       " ['2019-10-02 09:05:26.719571', 'Green'],\n",
       " ['2019-10-02 09:05:28.433857', 'Orange']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = read_raw_data('.')[0:5]\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dateutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.44721359, 0.25819889],\n",
       "       [0.4472136 , 0.51639778],\n",
       "       [0.4472136 , 0.        ],\n",
       "       [0.4472136 , 0.77459667],\n",
       "       [0.4472136 , 0.25819889]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please note: this is just a silly example of converting and normalizing, aka \"preprocessing stuff\"     \n",
    "def process_raw_data(raw_data) : \n",
    "    def convert(d) :\n",
    "        for datum in d : \n",
    "            dt = dateutil.parser.parse(datum[0])\n",
    "            ts = int(dt.timestamp())\n",
    "            c = Color[datum[1]].value\n",
    "            yield (ts, c)\n",
    "    processed_data = list(convert(raw_data))\n",
    "    normalized_data = normalize(processed_data, axis = 0)\n",
    "    return normalized_data\n",
    "\n",
    "process_raw_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_processed_data(storage_dir, processed_data) : \n",
    "    output_data_file = 'processed_data.csv'\n",
    "    output_path = os.path.join(storage_dir, output_data_file)\n",
    "\n",
    "    # Note: Clobbers existing processed data -- fine in this example\n",
    "    with open(output_path, mode='w') as f : \n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main() : \n",
    "    storage_dir = '.'\n",
    "    # Write some fake data to 'unprocessed_data.csv' -- normally data would be written via some external process\n",
    "    fake_data(storage_dir)\n",
    "\n",
    "    print(\"Beginning periodic data processing...\")\n",
    "    raw_data = read_raw_data(storage_dir)\n",
    "    processed_data = process_raw_data(raw_data)\n",
    "    write_processed_data(storage_dir, processed_data)\n",
    "    print(f\"Wrote {len(processed_data)} records\")\n",
    "    print(\"...Periodic data processing ended.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning periodic data processing...\n",
      "Wrote 39 records\n",
      "...Periodic data processing ended.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and scheduling a pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.65'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core\n",
    "azureml.core.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "#Larry's tenant\n",
    "interactive_auth = InteractiveLoginAuthentication(tenant_id=\"72f988bf-86f1-41af-91ab-2d7cd011db47\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "subscription_id = '65a1016d-0f67-45d2-b838-b8f373d6d52e'\n",
    "resource_group  = 'laobri_0925_ml'\n",
    "workspace_name  = 'laobri_schedule_pipelines'\n",
    "\n",
    "ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name, auth=interactive_auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Standard_DS1_v2',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 7168},\n",
       " {'name': 'Standard_DS2_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 7.0,\n",
       "  'maxResourceVolumeMB': 14336},\n",
       " {'name': 'Standard_DS3_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 28672},\n",
       " {'name': 'Standard_DS4_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 57344},\n",
       " {'name': 'Standard_DS5_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 114688},\n",
       " {'name': 'Standard_DS11_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 28672},\n",
       " {'name': 'Standard_DS12_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 57344},\n",
       " {'name': 'Standard_DS13_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 114688},\n",
       " {'name': 'Standard_DS14_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 229376},\n",
       " {'name': 'Standard_DS15_v2',\n",
       "  'vCPUs': 20,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 140.0,\n",
       "  'maxResourceVolumeMB': 286720},\n",
       " {'name': 'Standard_D1_v2',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 51200},\n",
       " {'name': 'Standard_D2_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 7.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D3_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D4_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D11_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D12_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D13_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D14_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 819200},\n",
       " {'name': 'Standard_D1',\n",
       "  'vCPUs': 1,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 3.5,\n",
       "  'maxResourceVolumeMB': 51200},\n",
       " {'name': 'Standard_D2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 7.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D3',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D4',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D11',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 14.0,\n",
       "  'maxResourceVolumeMB': 102400},\n",
       " {'name': 'Standard_D12',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 28.0,\n",
       "  'maxResourceVolumeMB': 204800},\n",
       " {'name': 'Standard_D13',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 56.0,\n",
       "  'maxResourceVolumeMB': 409600},\n",
       " {'name': 'Standard_D14',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 112.0,\n",
       "  'maxResourceVolumeMB': 819200},\n",
       " {'name': 'Standard_F2s_v2',\n",
       "  'vCPUs': 2,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 4.0,\n",
       "  'maxResourceVolumeMB': 16384},\n",
       " {'name': 'Standard_F4s_v2',\n",
       "  'vCPUs': 4,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 8.0,\n",
       "  'maxResourceVolumeMB': 32768},\n",
       " {'name': 'Standard_F8s_v2',\n",
       "  'vCPUs': 8,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 16.0,\n",
       "  'maxResourceVolumeMB': 65536},\n",
       " {'name': 'Standard_F16s_v2',\n",
       "  'vCPUs': 16,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 32.0,\n",
       "  'maxResourceVolumeMB': 131072},\n",
       " {'name': 'Standard_F32s_v2',\n",
       "  'vCPUs': 32,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 64.0,\n",
       "  'maxResourceVolumeMB': 262144},\n",
       " {'name': 'Standard_F64s_v2',\n",
       "  'vCPUs': 64,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 128.0,\n",
       "  'maxResourceVolumeMB': 524288},\n",
       " {'name': 'Standard_F72s_v2',\n",
       "  'vCPUs': 72,\n",
       "  'gpus': 0,\n",
       "  'memoryGB': 144.0,\n",
       "  'maxResourceVolumeMB': 589824}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.compute import AmlCompute\n",
    "list_vms = AmlCompute.supported_vmsizes(workspace=ws)\n",
    "list_vms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore, Experiment\n",
    "from azureml.data.data_reference import DataReference\n",
    "\n",
    "#blob_store = Datastore(ws, \"workspaceblobstore\")\n",
    "compute_target = ws.compute_targets[\"cpu-compute\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_config = RunConfiguration()\n",
    "compute_config.target = \"amlcompute\"\n",
    "compute_config.amlcompute.vm_size = \"STANDARD_D1_V2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "dependencies = CondaDependencies()\n",
    "dependencies.add_pip_package(\"scikit-learn\")\n",
    "compute_config.environment.python.conda_dependencies = dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Might be able to kill the cell below. I think `compute_config` works with my existing pipeline afterwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{>>\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "script_run_config = ScriptRunConfig(source_directory='/Users/lobrien 1/Documents/src/AzureDocs/MLOps/examples/pipeline-scheduling/preprocessing_src/', script=\"train.py\", run_config=compute_config)\n",
    "experiment = Experiment(workspace=ws, name=\"compute_target_test\")\n",
    "run = experiment.submit(config=script_run_config)\n",
    "run.wait_for_completion(show_output=True)\n",
    ">>}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(ws, 'MyExperiment') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'gpu_support' is no longer necessary; AzureML now automatically detects and uses nvidia docker extension when it is available. It will be removed in a future release.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step train.py [e4715bb7][5c925bd9-a46f-43d3-a2bb-033480842349], (This step is eligible to reuse a previous run's output)\n",
      "Submitted PipelineRun 196546a7-0372-48c0-90b9-f4c44433aa37\n",
      "Link to Azure Portal: https://mlworkspace.azure.ai/portal/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri_0925_ml/providers/Microsoft.MachineLearningServices/workspaces/laobri_schedule_pipelines/experiments/MyExperiment/runs/196546a7-0372-48c0-90b9-f4c44433aa37\n",
      "PipelineRunId: 196546a7-0372-48c0-90b9-f4c44433aa37\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri_0925_ml/providers/Microsoft.MachineLearningServices/workspaces/laobri_schedule_pipelines/experiments/MyExperiment/runs/196546a7-0372-48c0-90b9-f4c44433aa37\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 8a955c52-d28c-492c-87b3-5a825904d133\n",
      "Link to Portal: https://mlworkspace.azure.ai/portal/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri_0925_ml/providers/Microsoft.MachineLearningServices/workspaces/laobri_schedule_pipelines/experiments/MyExperiment/runs/8a955c52-d28c-492c-87b3-5a825904d133\n",
      "\n",
      "StepRun(train.py) Execution Summary\n",
      "====================================\n",
      "StepRun( train.py ) Status: Finished\n",
      "{'runId': '8a955c52-d28c-492c-87b3-5a825904d133', 'status': 'Completed', 'startTimeUtc': '2019-10-02T19:06:43.964274Z', 'endTimeUtc': '2019-10-02T19:06:44.029497Z', 'properties': {'azureml.reusedrunid': 'f13b9fba-dee2-41ea-92c2-58fb5dedad9e', 'azureml.reusednodeid': '7cd5e0b9', 'azureml.reusedpipeline': '1bdc9da6-f0f9-4831-b6ab-1308d0c574f7', 'azureml.reusedpipelinerunid': '1bdc9da6-f0f9-4831-b6ab-1308d0c574f7', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'e4715bb7', 'ContentSnapshotId': 'cdcec54f-95dc-4713-91c9-a54bfb3d31b7', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.pipelinerunid': '196546a7-0372-48c0-90b9-f4c44433aa37'}, 'inputDatasets': [], 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/azureml-logs/20_image_build_log.txt?sv=2018-11-09&sr=b&sig=idZgd8PdR8Hc8qGupAVZgdRJjKWX7KGBGy%2F0Ryyc1pw%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_897393bda6f63976877cb382cf7e1f421825d2bf812c8618b9e546c799fe413a_d.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/azureml-logs/55_azureml-execution-tvmps_897393bda6f63976877cb382cf7e1f421825d2bf812c8618b9e546c799fe413a_d.txt?sv=2018-11-09&sr=b&sig=IKuJHbVTGOUu3GzOOLeTvpvd%2B%2FW8aUE89bhZVhSwLPY%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r', 'azureml-logs/65_job_prep-tvmps_897393bda6f63976877cb382cf7e1f421825d2bf812c8618b9e546c799fe413a_d.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/azureml-logs/65_job_prep-tvmps_897393bda6f63976877cb382cf7e1f421825d2bf812c8618b9e546c799fe413a_d.txt?sv=2018-11-09&sr=b&sig=5k84F%2Bcw49avjzpWcUVu%2Bq4M2zobH3QRuB8JzuKGIh4%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/azureml-logs/70_driver_log.txt?sv=2018-11-09&sr=b&sig=bggHZ6YA0FkmOtRwRl0tNB%2Fo96j2Lw7FGC2fBOPLhuI%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r', 'azureml-logs/75_job_post-tvmps_897393bda6f63976877cb382cf7e1f421825d2bf812c8618b9e546c799fe413a_d.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/azureml-logs/75_job_post-tvmps_897393bda6f63976877cb382cf7e1f421825d2bf812c8618b9e546c799fe413a_d.txt?sv=2018-11-09&sr=b&sig=Di3O%2B7XqSrLrzM%2BPwaCSGqRE1JuNFv2qTSBOwTzP%2B4I%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r', 'logs/azureml/136_azureml.log': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/logs/azureml/136_azureml.log?sv=2018-11-09&sr=b&sig=xHk7aI21oNx5p8q%2Be%2Bac7jTeXJ6VWJP2GhS0il7pwz8%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r', 'logs/azureml/azureml.log': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/logs/azureml/azureml.log?sv=2018-11-09&sr=b&sig=vJp4bNAt9%2FW0CJ3fYgSraWvByCFV61l1qZX1VpZGef0%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/logs/azureml/executionlogs.txt?sv=2018-11-09&sr=b&sig=ZzijPoRv0%2Fn2t80MeEcJ7cl%2FVX%2F1zflZa4PQr1tOD6U%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/logs/azureml/stderrlogs.txt?sv=2018-11-09&sr=b&sig=jJ625i7XJWOBOTj0%2BAkXofcog97%2Fc4mxRCOR8En1sNQ%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.f13b9fba-dee2-41ea-92c2-58fb5dedad9e/logs/azureml/stdoutlogs.txt?sv=2018-11-09&sr=b&sig=cSl5slhzB0tW08VgeXo%2BXlDDDEO7dI0%2F9I%2FsxK67QbY%3D&st=2019-10-02T18%3A56%3A47Z&se=2019-10-03T03%3A06%3A47Z&sp=r'}}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '196546a7-0372-48c0-90b9-f4c44433aa37', 'status': 'Completed', 'startTimeUtc': '2019-10-02T19:06:43.337356Z', 'endTimeUtc': '2019-10-02T19:07:15.144636Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': None, 'runType': 'HTTP', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.196546a7-0372-48c0-90b9-f4c44433aa37/logs/azureml/executionlogs.txt?sv=2018-11-09&sr=b&sig=OCWveQ5%2FolPjK4yhkzaeDak2V4MCIqeuLdJlEHyD8z8%3D&st=2019-10-02T18%3A57%3A17Z&se=2019-10-03T03%3A07%3A17Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.196546a7-0372-48c0-90b9-f4c44433aa37/logs/azureml/stderrlogs.txt?sv=2018-11-09&sr=b&sig=tditcx4wrUFOHCcWbXpIw9VjpdIm5doJ3MT137agar8%3D&st=2019-10-02T18%3A57%3A17Z&se=2019-10-03T03%3A07%3A17Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://laobrischedule1812444618.blob.core.windows.net/azureml/ExperimentRun/dcid.196546a7-0372-48c0-90b9-f4c44433aa37/logs/azureml/stdoutlogs.txt?sv=2018-11-09&sr=b&sig=uq3CwArfnNCADpmogircef%2B08j4E921shCOjYBTwTxI%3D&st=2019-10-02T18%3A57%3A17Z&se=2019-10-03T03%3A07%3A17Z&sp=r'}}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [ PythonScriptStep(\n",
    "    script_name=\"train.py\",\n",
    "    arguments=[],\n",
    "    inputs=[],\n",
    "    outputs=[],\n",
    "    compute_target=compute_target,\n",
    "    runconfig = compute_config,\n",
    "    source_directory=\"/Users/lobrien 1/Documents/src/AzureDocs/MLOps/examples/pipeline-scheduling/preprocessing_src/\"\n",
    ") ]\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=steps)\n",
    "\n",
    "pipeline_run = experiment.submit(pipeline)\n",
    "pipeline_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\"My first scheduled pipeline\",f\"my description {str(datetime.now())}\", \"0.0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>My first scheduled pipeline</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri_0925_ml/providers/Microsoft.MachineLearningServices/workspaces/laobri_schedule_pipelines/pipelines/071d11e6-ad62-43c6-a8b5-7f4dccc7ed0a\" target=\"_blank\" rel=\"noopener\">071d11e6-ad62-43c6-a8b5-7f4dccc7ed0a</a></td><td>Active</td><td><a href=\"https://westus.aether.ms/api/v1.0/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri_0925_ml/providers/Microsoft.MachineLearningServices/workspaces/laobri_schedule_pipelines/PipelineRuns/PipelineSubmit/071d11e6-ad62-43c6-a8b5-7f4dccc7ed0a\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: My first scheduled pipeline,\n",
       "Id: 071d11e6-ad62-43c6-a8b5-7f4dccc7ed0a,\n",
       "Status: Active,\n",
       "Endpoint: https://westus.aether.ms/api/v1.0/subscriptions/65a1016d-0f67-45d2-b838-b8f373d6d52e/resourceGroups/laobri_0925_ml/providers/Microsoft.MachineLearningServices/workspaces/laobri_schedule_pipelines/PipelineRuns/PipelineSubmit/071d11e6-ad62-43c6-a8b5-7f4dccc7ed0a)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'071d11e6-ad62-43c6-a8b5-7f4dccc7ed0a'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_pipeline.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Schedule, ScheduleRecurrence\n",
    "\n",
    "recurrence = ScheduleRecurrence(frequency=\"Hour\", interval=1)\n",
    "schedule = Schedule.create(ws, name=\"TestSchedule\", pipeline_id=published_pipeline.id,\n",
    "                          experiment_name=\"MyExperiment\", recurrence=recurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To retrieve the pipeline later, use it's `id`: 071d11e6-ad62-43c6-a8b5-7f4dccc7ed0a\n"
     ]
    }
   ],
   "source": [
    "print(f\"To retrieve the pipeline later, use it's `id`: {published_pipeline.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can get the pipelines running in your workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(Name: TestSchedule,\n",
       " Id: 118d927d-efd7-4b22-a97d-8a1d7e8030c2,\n",
       " Status: Active,\n",
       " Pipeline Id: 071d11e6-ad62-43c6-a8b5-7f4dccc7ed0a,\n",
       " Recurrence Details: Runs every Hour), Pipeline(Name: TestSchedule,\n",
       " Id: aa69f03b-26ec-4bc3-a53e-9a33e0560ddc,\n",
       " Status: Active,\n",
       " Pipeline Id: 304dd02a-6d28-4338-ac53-5b6111705f42,\n",
       " Recurrence Details: Runs every Hour)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = Schedule.list(ws)\n",
    "ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PublishedPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_cleanup = False\n",
    "if do_cleanup : \n",
    "    p = PublishedPipeline.get(ws, id=\"?\")\n",
    "    p.disable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
